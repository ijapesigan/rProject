@Article{Efron-1979a,
  author = {Bradley Efron},
  date = {1979-01},
  journaltitle = {The Annals of Statistics},
  title = {Bootstrap methods: Another look at the jackknife},
  doi = {10.1214/aos/1176344552},
  number = {1},
  volume = {7},
  abstract = {We discuss the following problem: given a random sample $\mathbf{X} = \left( X_1 , X_2 , \dots , X_n \right)$ from an unknown probability distribution $F$, estimate the sampling distribution of some prespecified random variable $R \left( \mathbf{X}, F \right)$, on the basis of the observed data $\mathbf{x}$. (Standard jackknife theory gives an approximate mean and variance in the case $R \left( \mathbf{X}, F \right) = \theta \left( \hat{F} \right) - \theta \left( F \right)$, $\theta$ some parameter of interest.) A general method, called the ``bootstrap'' is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.},
  publisher = {Institute of Mathematical Statistics},
  keywords = {bootstrap, discriminant analysis, error rate estimation, jackknife, nonlinear regression, nonparametric variance estimation, resampling, subsample values},
}
